{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canterbury.txt\n",
      "dante.txt\n",
      "frankenstein.txt\n",
      "genesis.txt\n",
      "homer.txt\n",
      "ovid.txt\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "files = ['canterbury.txt','dante.txt','frankenstein.txt','genesis.txt','homer.txt','ovid.txt']\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    with open('data/'+file,'r', encoding='utf-8', errors='ignore') as b:\n",
    "        text.append(b.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = CountVectorizer()\n",
    "word_vector_counts = word_vector.fit_transform(text)\n",
    "term_freq_transformer = TfidfTransformer()\n",
    "term_freq = term_freq_transformer.fit_transform(word_vector_counts)\n",
    "target = [0,1,2,3,4,5]\n",
    "target_names = ['cant','dante','frank','gen','homer','ovid']\n",
    "model = MultinomialNB().fit(term_freq, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    print(file)\n",
    "    with open('data/'+file,'r', encoding='utf-8', errors='ignore') as b:\n",
    "        text.append(b.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procure essays\n",
    "\n",
    "import os\n",
    "\n",
    "names = ['ian','miles']\n",
    "\n",
    "essays = {}\n",
    "\n",
    "for name in names:\n",
    "    essays[name]={} # make dict called a name\n",
    "    for r, d, f in os.walk('./'+name+'/'): # get root, directory, and files from a name\n",
    "        for file in f: # take each file\n",
    "            if '.txt' in file: # if it's a text file\n",
    "                with open(r+file, 'r', encoding='utf-8', errors='ignore') as essay: # open\n",
    "                    essays[name][file.replace(name,'').replace('.txt','')] = essay.read() # place it at essays[name][title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "\t\tAfter hours and hours of incredible labor and fatigue I succeeded in understanding the  source of production for the various limbs of the skeleton in progress; nay, more, I became myself capable of fashioning segments of a magnificent automaton though the operation of this hollow shell of a machine . This newfound expertise instilled me with much rapture and satisfaction, emotions most gratifying for the time spent whirling in prolonged toil.\n",
      "\tIt was with these feelings I began the creation of the robot. The variety of sensations that enveloped me upon my first success were unimaginable. The distance between human and machine appeared ever so miniscule, a gap that I now possessed the capacity to surge beyond and forge such a contraption with my own two hands. A new creation would spiral into existence, one that could be manipulated, driven, and controlled by me and my colleagues, which would triumph over the others in the tournament the loomed overhead.\n",
      "\tThese thoughts supported my spirits, while I pursued my fabrication with unremitting ardor . My hands grew rugged and scraped with labor, and my person sagged from the perpetual days of unrelenting manufacture. Sometimes, on the very brink of completion, inaccuracies and miscalculations occured, spiralling the entirety of the element into insignificance; yet still I clung to the hope which I would succeed the production in the limited duration assigned to complete this task. My eyes swam with moisture and my head spun from tireless activity, and my legs began to buckle; but a resistless, and almost frantic impulse, urged me to return multiple times daily; I seemed to have lost all soul or sensation but for this one pursuit . => frank\n",
      "Probabilities:\n",
      "cant             dante            frank            gen              homer            ovid             \n",
      "0.16624466       0.16940725       0.18019723       0.1470456        0.16835894       0.16874632       \n"
     ]
    }
   ],
   "source": [
    "fake_docs = [essays['ian']['Frank']]\n",
    "fake_counts = word_vector.transform(fake_docs)\n",
    "fake_term_freq = term_freq_transformer.transform(fake_counts)\n",
    "\n",
    "predicted = model.predict(fake_term_freq)\n",
    "print('Predictions:')\n",
    "for doc, group in zip(fake_docs, predicted):\n",
    "    print('\\t{0} => {1}'.format(doc, target_names[group]))\n",
    "\n",
    "probabilities = model.predict_proba(fake_term_freq)\n",
    "print('Probabilities:')\n",
    "print(''.join(['{:17}'.format(name) for name in target_names]))\n",
    "for probs in probabilities:\n",
    "    print(''.join(['{:<17.8}'.format(prob) for prob in probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ian', 'miles'])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Cant', 'Frank', 'Homer', 'Dante', 'Origin'])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays['ian'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
